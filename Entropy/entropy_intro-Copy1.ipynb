{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy, Compression, and Huffman Variable Length Encoding\n",
    "stough 202-\n",
    "\n",
    "Images and videos can be quite large. At 60 frames per second, a 4K Ultra HD movie of 2 hours could require \n",
    "\n",
    "\\begin{equation*}\n",
    "((3840\\cdot2160)pixels \\cdot 3\\frac{byte}{pixel} = 24883200 \\frac{byte}{frame}\\\\\n",
    "\\frac{24883200 \\frac{byte}{frame}\\cdot60\\frac{frame}{second}\\cdot60\\frac{second}{minute}\\cdot120 minutes}{10^9\\frac{byte}{GB}} = 10749.5 GB,\n",
    "\\end{equation*}\n",
    "\n",
    "or about 163 blu-ray discs to store without compression. So clearly compression is a thing. \n",
    "\n",
    "Compression takes advantage of different kinds of redundancy in the signal. Images in particular have a lot of redundancy. Spatial and Temporal redundancy are characterized by the fact that most pixels are closely related their neighbors. This is due to the fact that any images of human interest are likely to have objects comprised of regions of similar color. *Temporal* redundancy is the video case, where a pixel over time changes little usually. \n",
    "\n",
    "Coding redundancy is the one we're dealing with here. Most images we consider are 3-channel images with 8 bits per pixel per channel. We need 8 bits to represent a value in $[0, 255]$. Variable-length encoding can take advantage of the differential frequency of certain pixel values over others, encoding more common pixels with fewer bits, and paying that off by using more bits to represent less common pixels.\n",
    "\n",
    "- **Compressibility**: The degree to which the information in an image or video can be represented using fewer bits. In the example above of the highly compressible 4K Ultra HD, we might say the *compression ratio* is ~160 (display size over storage size). \n",
    "- **Entropy**: a measure of the information content in a signal. \n",
    "    - signal: here, think of this as seeing each individual pixel in the image in order.\n",
    "    - Think of entropy as the surprise, or \"unpredictability\" of the signal. Each new pixel value $k$ in the signal gives you some information,\n",
    "    \\begin{equation*}\n",
    "    I(k) = -\\log_2(p(k)),\n",
    "    \\end{equation*}\n",
    "    where $p(k)$ is the probability of observing $k$ in the signal. For example, if the probability of observing $k$ is 1, as in 100\\% of all the pixels have the value $k$, then there is no information/surpise, or 0 bits, associated with observing it. If $p(k) = \\frac{1}{2}$, then that's 1 bit of information. (We won't consider the symbols $\\kappa$ that *never* show up, since observing such a symbol would be infinitely surprising :-). \n",
    "    - For our images in the range $[0, 255]$, we can measure the entropy or information content of the image as \n",
    "    \\begin{equation*}\n",
    "    \\tilde{H} = -\\sum_{k=0}^{255} p(k)\\log_{2}p(k)\n",
    "    \\end{equation*}\n",
    "    This is just an average of how many bits of information each newly observed pixel gives us, weighted by how likely that pixel value is. $p(k)$ is just the normalized histogram values.\n",
    "    \n",
    "In this notebook we'll explore Huffman variable-length encoding its effectiveness in some images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Notice I've added our own custom Huffman utilities `huff_utils` and [`scipy.stats.entropy`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html). Study `build_huff_tree` in particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "import skimage.color as color\n",
    "from ipywidgets import VBox, HBox, FloatLogSlider\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# For importing from alternative directory sources\n",
    "import sys  \n",
    "sys.path.insert(0, '../dip_utils')\n",
    "\n",
    "\n",
    "from huff_utils import (build_huff_tree,\n",
    "                        build_huff_encoder,\n",
    "                        build_huff_pair,\n",
    "                        load_huffable_image,\n",
    "                        test_tree_making)\n",
    "from matrix_utils import (arr_info,\n",
    "                          make_linmap)\n",
    "from vis_utils import (vis_rgb_cube,\n",
    "                       vis_hsv_cube,\n",
    "                       vis_hists,\n",
    "                       vis_pair,\n",
    "                       lab_uniform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A06 Test encoding/decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeImage(enI, decoder):\n",
    "    deI=[]\n",
    "    keys = decoder.keys()\n",
    "    i=1\n",
    "    while len(enI) >= i:\n",
    "        if enI[:i] in keys:\n",
    "            deI.append(decoder[enI[0:i]])\n",
    "            enI = enI[i:]\n",
    "            i=1\n",
    "        else:\n",
    "            i+=1\n",
    "    return deI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "982b44958f824d7b801dff466d72112d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19d783a8508>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I = plt.imread('../dip_pics/yes_small.jpg')\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huff_compress(I):\n",
    "    reI = np.zeros(I.shape)\n",
    "    for channel in range(3):\n",
    "        Ic = load_huffable_image(I[...,channel].copy())\n",
    "        encoder, decoder = build_huff_pair(Ic)\n",
    "        enI = ''.join(encoder[pix] for pix in Ic.ravel())\n",
    "        deI = decodeImage(enI, decoder)\n",
    "        reI[...,channel]=np.reshape(deI, Ic.shape)\n",
    "    return reI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reI = huff_compress(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837e16d0067b4760955adba149db9781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axarr = plt.subplots(1,2,figsize=(8,8))\n",
    "axarr[0].imshow(I.astype('uint8'))\n",
    "axarr[1].imshow(reI.astype('uint8'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statR(I):\n",
    "    #red\n",
    "    Ih = load_huffable_image(I[..., 0].copy())\n",
    "    encoder, decoder = build_huff_pair(Ih)\n",
    "    print(\"Channel Red statistics:\")\n",
    "    \n",
    "    #8-bit size\n",
    "    size_8bit = np.prod(Ih.shape)/1024\n",
    "    \n",
    "    #Huffman size\n",
    "    enIh = ''.join([encoder[pix] for pix in Ih.ravel()])\n",
    "    size_huff = len(enIh)/8/1024\n",
    "    \n",
    "    bins = np.arange(257)\n",
    "    freq, bins = np.histogram(Ih.ravel(), bins)\n",
    "    print(\"Red channel entropy is %.5f bits\" % entropy(freq, base=2))\n",
    "    print(\"Size at 8-bit encoding: %.2fKB.\" % size_8bit)\n",
    "    print(\"Size with huff encoding: %.2fKB, or %.2f bits per pixel\" % (size_huff, len(enIh)/np.prod(Ih.shape)))\n",
    "    print(\"---------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statG(I):\n",
    "    #green\n",
    "    Ih = load_huffable_image(I[..., 1].copy())\n",
    "    encoder, decoder = build_huff_pair(Ih)\n",
    "    print(\"Channel Grn statistics:\")\n",
    "    \n",
    "    #8-bit size\n",
    "    size_8bit = np.prod(Ih.shape)/1024\n",
    "    \n",
    "    #Huffman size\n",
    "    enIh = ''.join([encoder[pix] for pix in Ih.ravel()])\n",
    "    size_huff = len(enIh)/8/1024\n",
    "    \n",
    "    bins = np.arange(257)\n",
    "    freq, bins = np.histogram(Ih.ravel(), bins)\n",
    "    print(\"Grn channel entropy is %.5f bits\" % entropy(freq, base=2))\n",
    "    print(\"Size at 8-bit encoding: %.2fKB.\" % size_8bit)\n",
    "    print(\"Size with huff encoding: %.2fKB, or %.2f bits per pixel\" % (size_huff, len(enIh)/np.prod(Ih.shape)))\n",
    "    print(\"---------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statB(I):\n",
    "    #blue\n",
    "    Ih = load_huffable_image(I[..., 2].copy())\n",
    "    encoder, decoder = build_huff_pair(Ih)\n",
    "    print(\"Channel Blu statistics:\")\n",
    "    \n",
    "    #8-bit size\n",
    "    size_8bit = np.prod(Ih.shape)/1024\n",
    "    \n",
    "    #Huffman size\n",
    "    enIh = ''.join([encoder[pix] for pix in Ih.ravel()])\n",
    "    size_huff = len(enIh)/8/1024\n",
    "    \n",
    "    bins = np.arange(257)\n",
    "    freq, bins = np.histogram(Ih.ravel(), bins)\n",
    "    print(\"Blu channel entropy is %.5f bits\" % entropy(freq, base=2))\n",
    "    print(\"Size at 8-bit encoding: %.2fKB.\" % size_8bit)\n",
    "    print(\"Size with huff encoding: %.2fKB, or %.2f bits per pixel\" % (size_huff, len(enIh)/np.prod(Ih.shape)))\n",
    "    print(\"---------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCompressionStats(filename):\n",
    "    I = plt.imread(filename)\n",
    "    statR(I)\n",
    "    statG(I)\n",
    "    statB(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel Red statistics:\n",
      "Red channel entropy is 5.94605 bits\n",
      "Size at 8-bit encoding: 39.85KB.\n",
      "Size with huff encoding: 29.80KB, or 5.98 bits per pixel\n",
      "---------------\n",
      "Channel Grn statistics:\n",
      "Grn channel entropy is 5.79043 bits\n",
      "Size at 8-bit encoding: 39.85KB.\n",
      "Size with huff encoding: 29.02KB, or 5.83 bits per pixel\n",
      "---------------\n",
      "Channel Blu statistics:\n",
      "Blu channel entropy is 6.26437 bits\n",
      "Size at 8-bit encoding: 39.85KB.\n",
      "Size with huff encoding: 31.36KB, or 6.30 bits per pixel\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "getCompressionStats('../dip_pics/yes_small.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
