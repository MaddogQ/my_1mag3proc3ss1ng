{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Distributions, Gaussian and Uniform\n",
    "stough 202-\n",
    "\n",
    "In the [matplotlib tutorial](./matplotlib_tutorial.ipynb) we saw how to produce a histogram of color distribution in an image. These histograms represent the [probability distribution](https://en.wikipedia.org/wiki/Probability_distribution) on color; that is, the probability of a particular color in an image corresponds to the height of the histogram at that color (given the histogram of that image). \n",
    "\n",
    "In this demo we'll look at Uniform and Gaussian probability distributions, and what corresponding \"random\" images look like.\n",
    "\n",
    "- [Uniform](#uniform)\n",
    "- [Gaussian](#gaussian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "We'll produce random numbers using numpy's updated random-number-generation techniques. Read more about it [here](https://numpy.org/doc/stable/reference/random/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# For importing from alternative directory sources\n",
    "import sys  \n",
    "sys.path.insert(0, '../dip_utils')\n",
    "\n",
    "import matrix_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "rng = default_rng() # could add parameter \"seed=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(PCG64) at 0x220CB5235E8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point the object `rng` is our random number generator, and it has been seeded (with the current time for example) to produce different random sequences each run through this notebook. You could also seed the default random number generator to ensure the same random sequence (good for debugging). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='uniform'></a>\n",
    "## Uniform Random Distribution \n",
    "When you think of the word \"random,\" you probably mean that any outcome of the \"random\" process is equally likely. Let's say we're generating integers between 0 and 255 (inclusive). We would expect over many samples that no number is a lot more likely than any other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rng.integers(0, high=256, size=2**20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1caafca1591c4dbe80a49760ba6ad339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "unif_counts, _, _ = plt.hist(X, bins = np.arange(257));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-508797f551e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmatrix_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marr_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "matrix_utils.arr_info(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above we generate about 1M samples in the range [0,255]. In fact we generate $2**20 = 1048576$. Since these random numbers are split among $256 = 2**8$ possibilites, that means on average we should get $2**12 = 4096$ hits for each output integer. What makes the randomness *uniform* is that most of the bins have about the same number of outcomes, hovering near 4K as expected.  \n",
    "\n",
    "- Little complication in generating the plot: [`plt.hist`](https://matplotlib.org/3.3.3/api/_as_gen/matplotlib.pyplot.hist.html) expects the `bins` argument to include both left end of the first bin *and* the right end of the last bin. Since [`arange`](https://numpy.org/doc/stable/reference/generated/numpy.arange.html) provides the sequence $[0, N)$ exclusive, we call it with 257 to make sure we get all the way to $[0,...,256]$.\n",
    "\n",
    "Now let's generate an image of uniform random colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_uniform = np.stack([rng.integers(0,256,2**14).reshape(2**7,2**7) for i in range(3)], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1978bad0f44820b1800021bff8509b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(I_uniform);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49152,), dtype('int64'), 0, 255)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_utils.arr_info(I_uniform.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is what a truly random image looks like. \n",
    "\n",
    "- Is it anyhing like the images we ourselves capture, communicate to each other, attempt to study? \n",
    "- What is missing from it?\n",
    "- What does this say about the kinds of images that we actually care about?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gaussian'></a>\n",
    "## Gaussian Random Distribution\n",
    "\n",
    "There is a different kind of random that is more practically interesting in the world: the [Gaussian, or Normal, Distribution](https://en.wikipedia.org/wiki/Normal_distribution), also called the Bell Curve. Many phenomena we deal with every day often [closely follow the normal distribution](https://www.mathsisfun.com/data/standard-normal-distribution.html), including heights, measurement errors, blood pressure, test scores. Here we'll take a look a couple of Guassian-distributed samples.\n",
    "\n",
    "As an aside, most everything that we try to model with a Gaussian is better modelled with some sort of skew normal, [weibull](https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.weibull.html), or [pareto](https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.pareto.html). These distributions have a heavier tail on one side than the other, common when there is some physical limit on the measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rng.standard_normal(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5b3afa95ef45dcb49639386c88c41c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "plt.hist(X, bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0027962294881986134, 0.9970050011525031)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean(), X.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we sample from a [`standard_normal`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.standard_normal.html), which you can see has a mean of 0 and a variance (average square distance from the mean) of 1, symbolized with $\\mathcal{N}(\\mu = 0,\\sigma^{2} = 1)$. We can reposition this kind of distribution anywhere we want by \n",
    "\n",
    "- adding a constant, to change the mean: $C + \\mathcal{N}(\\mu,\\sigma^{2}) \\sim \\mathcal{N}(C + \\mu,\\sigma^{2})$\n",
    "- multiplying by a constant, to change the variance: $K*\\mathcal{N}(\\mu,\\sigma^{2}) \\sim \\mathcal{N}(\\mu,K^2\\sigma^{2})$\n",
    "\n",
    "Using the above rules, we could make a Gaussian distributed image in the range $[0,255]$. We can also use numpy's [`normal`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.normal.html) to do the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar idea using our rules.\n",
    "# X_im = (128 + 30*X).clip(0,255) \n",
    "I_normal = np.stack([rng.normal(128,30,2**14).reshape(2**7,2**7) for i in range(3)], axis=2)\n",
    "I_normal = np.uint8(I_normal).clip(0,255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4624376606fa48239e9fbca043e963c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "norm_counts, _, _ = plt.hist(I_normal.ravel(), np.arange(257));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4768e4fdada34d149fee80e0f67fad2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1,2, figsize=(6,3), sharex=True, sharey=True)\n",
    "ax[0].imshow(I_uniform)\n",
    "ax[0].set_title('Uniform Random')\n",
    "ax[1].imshow(I_normal)\n",
    "ax[1].set_title('Gauss Random');\n",
    "\n",
    "[a.axes.get_xaxis().set_visible(False) for a in ax];\n",
    "[a.axes.get_yaxis().set_visible(False) for a in ax];\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above cells, we plot the distribution of the Gaussian normal image (`I_normal`) and then show both the uniform (`I_uniform`) and normal images side by side. \n",
    "\n",
    "You should immediately notice that the \"Gauss Random\" image is much more bland, or muted in its tones, than the \"Uniform Random\" image. This kind of difference is related to [*contrast*](https://en.wikipedia.org/wiki/Contrast_(vision)). Contrast measures how distinguishable different image parts are from one another. In `I_normal`, most pixel intensities in red, green, and blue hover around 128. This results in a middling gray tone to the whole image, with neighboring pixels only mildly distinguishable from one antoher, especially compared to `I_uniform`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the two distributions together\n",
    "A little bit of matplotlib-ary to show the two distributions together without y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the heights.\n",
    "norm_counts = norm_counts/norm_counts.sum()\n",
    "unif_counts = unif_counts/unif_counts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5955541531442f8a4dbe61c159db8cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax1 = plt.subplots(figsize=(7,3))\n",
    "ax1.bar(np.arange(256), unif_counts, alpha=.5)\n",
    "\n",
    "plt.bar(np.arange(256), norm_counts, alpha=.5);\n",
    "ax1.get_yaxis().set_visible(False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forthcoming\n",
    "Maybe an interactive plot on I_normal with a variance slider and the resulting image. Will have to take better care than above on the pixels that get clipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
